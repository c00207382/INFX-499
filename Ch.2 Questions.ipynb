{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These answers are the ones found in the text.  I am comfortable enough to be able to follow and understand the answers found in the text, but not comfortable enough to create my own versions of them.  Any thing I attempted failed.\n",
    "\n",
    "# 1. Try a Support Vector Machine regressor with various hyperparameters such as kernel=\"linear\" or kernel=\"rbf\".  Don't worry about what these hyperparameters mean for now.  How does the best SVR predictor perform?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'kernel': ['linear'], 'C': [10., 30., 100., 300., 1000., 3000., 10000., 30000.0]},\n",
    "    {'kernel': ['rbf'], 'C': [1.0, 3.0, 10., 30., 100., 300., 1000.0], 'gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]},\n",
    "]\n",
    "\n",
    "svm_reg = SVR()\n",
    "grid_search = GridSearchCV(svm_reg, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search.fit(housing_prepared, housing_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear works best with these values in the SVR, this is due to the current c values.  Replacing the c values may end up with a different outcome.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Try replacing GridSearchCV with RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon, reciprocal\n",
    "\n",
    "param_distribs = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': reciprocal (20,200000),\n",
    "    'gamma': expon(scale=1.0),\n",
    "}\n",
    "\n",
    "svm_reg = SVR()\n",
    "rnd_search = RandomizedSearchCV(svm_reg, param_distributions=param_distribs, n_iter=50, cv=5, scoring='neg_mean_squared_error', verbose+2, random_state=42)\n",
    "rnd_search.fit(housing_prepared, housing_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This random search provided better parameters for a RBF kernel.  Random search seems to be more efficient than grid, as it finds better parameters in the same amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Try adding a transformer in the preparation pipeline to select only the most important attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def indices_of_top_k(arr, k):\n",
    "    return np.sort(np.argpartition (np.array(arr), -k) [-k:])\n",
    "\n",
    "class TopFeatureSelector(BaseEstimator, TransormerMixin):\n",
    "    def _init_(self, feature_importances, k):\n",
    "        self.feature_importances = feature_importances\n",
    "        return self.k = k\n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_indices_ = indices_of_top_k(self.feature_importances, self.k)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[:, self.feature_indices_]\n",
    "    \n",
    "k=5\n",
    "top_k_feature_indices = indices_of_top_k(feature_importances, k)\n",
    "top_k_feature_indices\n",
    "np.array(attributes)[top_k_feature_indices]\n",
    "sorted(zip(feature_importances, attributes), reverse=True)[:k]\n",
    "\n",
    "preparation_and_feature_selection_pipeline = Pipeline([('preparation', full_pipeline),('feature_selection', TopFeatureSelector(feature_importances, k))])\n",
    "housing_prepared_top_k_features = preparation_and_feature_selection_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is pretty confusing at first, but it uses the existing pipeline then runs that pipeline into a new one that adds the transformer which only grabs the valuable attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try creating a single pipeline that does the full data preparation plus the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_select_and_predict_pipeline = Pipeline([\n",
    "    ('preparation', full_pipeline),\n",
    "    ('feature_selection', TopFeatureSelector(feature_importances, k)),\n",
    "    ('svm_reg', SVR(**rnd_search.best_params_))\n",
    "])\n",
    "\n",
    "prepare_select_and_predict_pipeline.fit(housing, housing_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pipeline gathers all the data, and makes a prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Automatically explore some preparation options using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{\n",
    "    'preparation_num_imputer_strategy': ['mean', 'median', 'most_frequent'],\n",
    "    'feature_selection_k': list(ranfe(1, len(feature_importances) +1))\n",
    "}]\n",
    "\n",
    "grid_search_prep = GridSearchCV(prepare_select_and_predict_pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2)\n",
    "\n",
    "grid_search_prep.fit(housing, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results from this indicate that most_frequent is the best preparation option."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
